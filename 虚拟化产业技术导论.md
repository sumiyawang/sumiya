```
风起

        2019年是特殊的一年，世界即将发生重大变革，也正直云产业正极速扩张，当时的大中小企业跑步入场堪比牛市初期的投资热情，同时客户的研发办公室经常也充斥着加班声和质疑声。作为云服务提商，我们也切实感受到了来自公有云和自研的巨大压力与挑战，究其原因主要是客户的上云前的各种业务组件已经与原先的生产环境深度绑定，在上云的过程中任何一个内核参数或者系统配置文件的改动，都有可能让客户业务执行不符合预期。例如在云厂商对外呈现的镜像里，某些tcp参数往小了调会影响网络吞吐量，往大了调则会影响包时延。如何让大部分业务以最小感知平稳上云，如何评估发布特性优化的影响和收益，如何保证云环境和物理环境性能一致，是一门艺术，也是厂商的核心竞争力。

        近些年，随着马斯克喊出“X celebrates 60% savings from cloud exit”，上云下云之争被推上了风口浪尖。一些公司有能力自建IDC后，从全链路成本控制和长期利益来看往往会回归下云的方案。但是对广大的中小企业和个人来说，或许是需要服务节点灵活扩容缩容，或许是需要快速部署业务，或许是要调整服务器CPU内存磁盘网络资源，亦或许仅仅是需要一个公网IP的机器，上云是便捷首选。可以预见，在今后相当长的一段时间内，只要还有业务需要直接在OS上运行代码，云服务器将会越来越成熟，用户使用也会越来越便捷。至于后期各大云厂商会不会实现技术路线和商业化的统一；今后业务会不会越来越轻量化从而脱离OS，则超出了此文讨论的技术范畴，有兴趣的读者可以进一步交流。

论剑

        在腾讯一切以用户为本。从我和客户的接触、和业界的交流来看，我总结云服务主要围绕着这五个维度的用户体验：服务稳定、极致性能、数据安全、弹性伸缩、高效部署。可以说每个方向既是云平台的生命线，也最容易打出差异化和积累技术壁垒。

用户口碑之争——服务稳定：

        我总结一个简单衡量云服务稳定性模型包含两点：云平台的平均对外提供服务时间+算力波动差异。从影响对外服务时间的因素来看，主要可分为服务器宕机、服务器断网/IO hung、重启服务时延。

        先说宕机原因，其可粗分为软件原因和硬件原因，软件再细分又可划分为host kernel 问题，guset kernel问题等；硬件细分又有内存问题，CPU问题等。其中涉及到很多vmcore分析技术，热补丁修复技术，RAS软硬件协同技术的细节。从问题分析的角度来说，现阶段主要是人工分析coredump/vmcore，我之前有段时间写过类似的归类分析km，但后来发现不太可能一条一条列举出所有的排查方法，所以这类问题对个人经验值比较看重，且生产环境成规模之后数量也不会少。一个创新的解决方案是一些厂商将问题判定和AI相结合，由经验数据训练出大师级分析器，把大量当宕机数据自动分析出可能的原因，然后再将极少量有异议的交给人工干预，该技术成熟之后，未来厂商的运营成本确实可以大幅缩小。从修复软件缺陷的角度来讲，业界常用热补丁技术，包括用户态进程热补丁，内核热补丁，CPU微码补丁。从规避硬件问题的角度来讲，linux RAS系统可进行物理损坏页的隔离、终止被影响的进程。上层调度组件也可基于OS异常信息及时进行云服务器热迁移等，各厂商在开源软件稳定性一致的情况下，硬件质量一致的情况下，上层手段如何做到对客户的影响最小，带数据机型故障后是否能做到最大程度保存数据，是今后的一个方向。

        服务器断网/IO hung的触发更为多样化，因为该问题和host软件强相关，且大多数是和发布强相关。近几次一些知名云厂商的重大事故几乎都是由该问题导致，一次配置文件的变更，一次服务器的流量切换等，都可能产生未预料的问题。我认为针对此类问题是无法完全避免的，毕竟只要是人为主动进行的操作就有犯错的可能，并且问题可能出现在任何一个组件任何一行代码中。转换思路我们可以从流程侧最大程度规避这个问题：可以将一些高危需求项目拉长和分解，想象成《三体》中的秦始皇旗帜方阵概念一样，只要每个单元做的事越简单就越难以出错。比如一个完整的需求安全链路应该包括：需求对接，需求评估，需求分析，职责划分，方案设计，方案评审，方案实现，环境评估，用例评估，影响评估，测试评审，测试验证，测试报告，发布评审，发布灰度，发布策略，发布验证，发布监控等，用户反馈等。虽然看起来流程很冗长，但如果在需求评估或实现中确实觉察到有高危信号，完备的流程将是挽救损失最后一道防线，这部分质量建设对云厂商来说也至关重要。

        如果真的发生了非预期的突发故障，平均对外提供服务时间提醒我们还要保证服务恢复时间，服务重新拉起时间等。这部分常见的工业化对策是容灾演练。事实上据我所知历史发生过一些重大故障后，有些团队确实提高了容灾演练的频次。如果想做一些主动缩减恢复时间的工作，常见是备份系统，不论是业务主备切换还是将云服务器做快照备份，都是可能的方案，不同的业务有自己的技术细节不再赘述。值得一提的是我之前了解到有一些友商在宣称发生云服务器宕机后恢复时间在秒级，猜测是在底层使用了内存快照备份方案，但成本和收益如何平衡则是一门艺术。

        衡量稳定性指标的第二点，算力波动指标，是指客户在使用过程中产生非预期的性能抖动，造成客户业务对外提供服务的qps产生抖动。大多数业务自身在负载均衡设计上已经考虑到了这一点，允许一定程度的性能下降的同时保持对外吞吐量不变，但云厂商仍在一直追求减轻这里的影响。产生性能服务抖动的原因和针对性的方案很多，我觉得有几种比较有趣的优化领域可以关注：热迁移性能优化、硬件资源隔离优化。

        服务器热迁移是在云服务器对外服务不中断的前提下变更宿主机，极致目标是让客户完全无感知。在虚拟化的实现上，为了减少锁开销而使用预构建ept页表；为了减少脏页访问导致vmexit/trap而使用硬件PML/DBM标脏是两种有发展潜力和有技术挑战的解决方案。硬件资源隔离这里，前几年被诟病的云上内存带宽串扰业界硬件厂商也有了qos解决方案，较细粒度的还有ipi广播隔离方案，tlbinv指令局部广播方案等，也都在往极致细粒度的隔离靠拢。

产品对标之争——极致性能：

        当新一代机型推出时，对外呈现的算力上较上一代有较大提升，以此提升产品竞争力。除此之外，虚拟化技术一直致力于缩减物理机和虚拟机之间的性能gap。大家最开始关注的是最基础的CPU/访存性能，这些当然是新机型发布的基础指标。另外新机型会使用一些针对性的加速器，技术侧也会关注外设/中断性能，原因是这部分软件参与的较多，有较大的性能提升可能。

        外设性能提升现在比较主流的方案是基于iommu的vfio直通方案，比如guest的dma操作可通过kvm管理的iommu的映射直接访问host设备内存。但是目前主流的还是基于viommu方案，guest对iommu的配置还是会有软件参与。有几种架构已经在讨论直接对guest可用的硬件MMU方案，比如AMD/ARM SMMU的S1/S2两级硬件方案，目前上游也还没有完全利用上该特性，感兴趣可关注。

        中断的发展历程也是经历由软件——半硬件——全硬件参与，在一些中断密集型业务比如IO密集型、低延迟响应场景，实测下来这里的性能提升有25%甚至100%以上。这里不同架构的具体方案差异较大，但总体来讲都是软件负责初始控制面，硬件负责中断数据面，kvm有一个整体框架，不同的架构去编写相关回调函数，下文中会重点讲讲这里的差异。还有另一种中断性能提升的着眼点是使用硬件直接注入与virtio方案相结合，可提升一些基于virtio的存量机型的性能，感兴趣可关注。

客户信任之争——数据安全：

        用户的数据安全对云厂商来说是重中之重，任何和数据相关的问题都是最敏感、最高优先级、最大资源处理。这里简单介绍一些数据防丢失，数据加密，大模型加密技术的前景。

        由于磁盘的物理寿命限制、机房的极小概率事故等，云上多采用磁盘多副本技术来解决单点数据损失的风险，同时磁盘快照也为客户的数据自恢复提供了可能。但数据量过于庞大之后成本也需要纳入考虑，如何在高效的完成磁盘快照的同时减少成本也是一门学问。

        在对数据有高保密性要求的业务中，可采取国密算法对云服务器落盘的数据进行虚拟化层加密，这样从host宿主机环境，到网络传输链路，到云盘的仓库落盘都是加密后的数据。结合商业化的加密算法，可大幅减少性能开销。同时，在虚拟化软件层也可实现数据防篡改技术，保障 guest 落盘的写和读一致，这部分同样有校验元数据的存在，如何最小的校验元数据完成最大的磁盘校验范围合精度也值得研究。

        另外随着生成式AI的崛起，我们也需要布局和关注大模型的加密。现阶段云厂商，大模型厂商，数据厂商之间相互独立，比如用户可能会把自己敏感数据放在大模型里面做推理，大模型厂商也对自己调试好的模型有防泄漏的要求，此时云厂商需要构建一个绝对互信的环境。我调研过 NV GPU 有内部加密功能，结合cuda的加密模块，再结合intel/AMD的可信环境背书，可以搭建出一个较为理想的方案，感兴趣可阅读更多材料。

动态资源之争——弹性伸缩：

        灵活可变是云环境相比于IDC的巨大优势，这部分主要是比较上层的大盘资源调度策略，有一些开源的资源管理框架如openstack，腾讯云自研的VStation，不再细述。对于底层来说，可以关注如何提升一个宿主机、一个云服务器最大支持的弹性设备数、高密度场景下对一个磁盘/网卡 plug/unplug 后能否做到性能/状态的幂等性、cpu/内存能否做到运行时弹性变配等技术。这里的技术方向从我之前的调研和开发经历来看总体比较深入，设计到kvm的中断框架限制点，也涉及到qemu的pci设备框架，内存布局的更新算法等。想要做的好需要考虑诸多细节，但一旦产品成形带给用户的价值也很大。

上云门槛之争——高效部署：

        业务对于环境的变更是很敏感的，越能将部署门槛降到最低越能吸引增量业务。比如从产品层面来讲，现在较流行一种轻型云服务（云函数），可以直接提交代码按需执行。此外常见的一些需求是大部分业务代码需要从物理机迁移到云环境，这部分大多数可直接迁移，极少数情况下可能由于性能不一致导致适配物理环境的业务框架运行结果非预期。另外一部分业务可能需要换架构迁移，换虚拟化环境迁移，这里没什么太好的一揽子解决方案，比较偏工程化，研发人员的自身素质和经验就是客户的口碑来源。

论道

        当我们在讨论云服务器的技术路线时，绕不开硬件辅助虚拟化。事实上早期虚拟化技术是纯软件模拟，此时多用于学术研究。当硬件可以辅助虚拟化行为，让guest和host执行性能没什么差异时，才能搭建起真正能商用的云产业。这里有一个比较有趣的现象：不同架构虽然都想实现简单易用高效的虚拟化技术，但他们从底层分析和解决问题的方式其实有较大差异。了解这些有助于我们从技术角度对硬件架构做选型比较，有助于评估软件的可维护性，可扩展性，未来发展方向。注：本章难免包含一些个人观点，读者可辨证的阅读。

        硬件辅助虚拟化最开始面临的一个经典的问题是guest和host的如何实现内存页表的隔离。最开始社区使用原始的CPU地址翻译模块，直接把guest va翻译为host pa，仅仅维护一套虚拟化页表来实现混合页表。后来觉得维护极其复杂，intel 从Nehalem 率先支持host/guest各自维护va-pa的页表，中间衔接由硬件去自动查找翻译。后来几大架构几乎都沿用了这种方式。

        RISC架构CPU针对此类问题开始出现分歧。比如在龙芯早期支持虚拟化的MIPS架构CPU中，仅实现了虚拟化的基本root/non-root状态，而没有自动处理地址翻译。这部分硬件自动查找和替换 tlb 的相关指令和算法是手工编写实现的，因为早期MIPS64架构的设计思路就是RISC指令集的硬件逻辑必须做到极简便于CPU厂商设计实现，而稍微高级点的功能则由硬件提供接口软件编码实现。或许有些人可能会觉得这种设计哲学非常原始和低效，但是请不要忘记指令集设计者的初衷也是尽可能降低CPU厂商的门槛、拥抱开源，是为不被某些一家独大的公司所垄断而迈出尝试性的一步，虽然可能微弱可能是弯路但也点燃了星星之火，这种设计思想后来也深刻影响了RISC-V。随着技术的积累，近几年龙芯比较新的loongarch架构的CPU也将这部分逻辑硬件化了。

        另一个比较经典的RISC架构是ARM。在ARM最开始发布服务器级别ARM64架构后，armv7同时带入了对虚拟化的支持，此时硬件实现了EL0-EL2异常模式来区分guest和host，类似x86的root/non-root，还有二级页表翻译，由写寄存器进行中断注入等。这些是最基本的虚拟化支持，达到了arm能用虚拟化的阶段，其实这里也是沿用聊RISC的设计思路：硬件保证能用和逻辑闭环，具体的细节软件再去优化。后来armv8版本开始支持对异常级别切换加速（vhe），支持MSI（LPI），中断直通（gicv4）等，达到高效虚拟化的阶段。这里硬件去接管软件通路应该也是商业化竞争导致设计人员向x86看齐，毕竟相比x86起步很晚，有些关联路径如果纯依赖软件去修补完善几乎没有什么竞争力。

        综上可见业界在虚拟化的技术路线是硬件厂商承载越来越多的数据通路任务，由云软件厂商负责控制面任务。在此过程中，也是软件架构师收集到性能瓶颈转而向硬件研发团队反馈的一个过程。

        另一个绕不开的例子是中断子系统，中断也是最能反应架构设计思想差异性。在基础中断中，x86 由于历史包袱，历史上出现的每种pic、APIC、ioapic、LAPIC这种繁琐的中断控制器必须由kvm-qemu虚拟化带进现在的产品中，与此同时arm64没有什么历史包袱，直接将中断按类型划分为SGI，PPI，SGI，一套distributor（类似ioapic）-redistributor（类似LAPIC）控制器基本上就能完全覆盖。

        我们先来对比普通中断的访问：x86对 LAPIC 的访问上是使用一个内存页去访问，称为APIC-access page，在虚拟化时使用一套virtual-APIC page，由kvm将其地址写入VMCS中，guest 就能在很多情况下不用vm-exit去访问。与此同时arm64虚拟化没有vmcs，没有中断page之类的东西，arm需要做的就是不停的写寄存器，基本上host和guest寄存器都有自己的一套，寄存器名字由CPU所处的特权级状态EL1/EL2区分（类似root/non-root），由硬件实现和特权级决定读写是否导致退出。一个典型的例子是guest写自己的定时器寄存器不会导致trap（vm-exit），这都是arm从一开始诞生就善于堆寄存器资源的成果。但是这种寄存器模式相比内存模式也有其他问题，因为寄存器资源始终是有限的，每个寄存器物已经在每个特权级别尽其用不可修改，所以遇到了NMI的场景arm在以前是束手无策的，但是NMI又太重要了，最近有些厂商才有一些绕过的方法，比如华为pseudo NMI等。

        在竞争激烈的MSI中断处理领域，网络/IO密集型业务的性能上限很大程度上取决于MSI中断处理的效率，这也是云服务提供商的核心竞争力之一。Intel通过VT-d和IOMMU实现了MSI中断可以直接发送到virtual-APIC page，这样guest可以无需退出（exit）即可感知到中断，这种机制被称为posted-interrupt。在基于VFIO框架的情况下，当MSI中断到达时，首先被IOMMU处理，IOMMU根据MSI索引查找中断映射表，这部分在guest启动时已通过MSI配置空间预先配置，并通过VT-d的IRTE表项实现映射。接着，系统会定位到具体的VMCS，并进一步找到virtual-APIC page。根据VMCS的状态（是否为活跃状态NV），系统决定是直接更新到virtual-APIC page还是通过中断唤醒vCPU。

        在ARM64架构中，对应的关键硬件包括ITS和redistributor，其实现逻辑相较于x86更为复杂。设备首先将MSI发送到ITS，ARM的MSI中仅包含eventID和deviceID，不包含任何CPU相关信息。ITS会查找device table和ITT，进一步索引eventID。在初始化时，构建映射表是通过针对ITS设备的VMAPTI指令完成的。查表后，如果发现中断是虚拟中断，则将其发送到redistributor。Redistributor包含vCPU的pending表项（VPT）和配置表项，根据vCPU是否在线决定是直接写入VPE的pending表项还是产生一个doorbell中断以唤醒vCPU。虽然这一整套流程是硬件自动完成的，但软件必须使用ITS的几种命令预先将VPE-VPT（VPE是硬件层面的vCPU概念）、ITS-VPE、ITS-LPI（MSI）相关联，这一过程相当繁琐。在vCPU切换时，Intel通过修改VT-d的IRTE来应对，而ARM则需要向ITS发送指令来修改VPE-VPT等配置。这显示了ARM在设计上倾向于将整个过程细分为多个小设备，并通过软件来完成每个子系统的衔接，尤其是对ITS设备的特殊指令配置，整个过程几乎不涉及统一的内存管理中断。

        在我看来，以arm64为代表RISC指令集在虚拟化的解决方案包含了很多嵌入式的思想，还是稍微缺少了一些统一框架的能力，这对多架构之间横向可维护，可扩展的对比还是有一定的影响。但是对于个人开发者和研发团队，一旦了解掌握这些技术也可成为很厚的技术壁垒，毕竟各种架构都有自身的用武之地。

修心

        最后，我想讨论下一名优秀的云研发工程师应该具备怎样的素质，或者对新人来说其健康的成长路线应该是什么样的？

        对腾讯来说，打磨一款优秀的产品是业务的核心使命。在我参与的大部分项目中，对研发的要求是不仅要完成技术上的研发工作，也需要当一名好的owner。在一些项目的要求下，我会做一些前期产品技术调研工作，多团队运行流程设计，制定发布策略，收集客户反馈。刚毕业的我是不理解的，学院派那套东西会认为完成和实现好技术方案就是最大的使命。后来有了直接和客户交流的机会，也有作为甲方和其他硬件厂商直接对接的经历，我认为业界的很多研发工作确实有闭门造车之嫌，可能投入了很多精力但并不是客户想要的，或者我们研发的产品形态客户其实并不认可。我们必须和客户打成一片，了解客户真正想要的功能，了解客户在意什么，不在意什么。

        记得早先做NVIDIA大模型机密计算需求时，我们和产品团队带着TEE的技术架构拜访了WPS AI部门的技术领导。我在前期做了很多TEE的最小单元的技术细节调研，这部分NV和intel/amd联手花了很多心思去实现逻辑完备链，在研发看起来是很有技术难点和工作量的，但是到了现场客户更关注整个链路的安全，还有一些合规的技术挑战，包括数据的上传下载存储安全等，具体云服务器的执行单元TEE硬件安全的技术逻辑对他们来说只是其中一个环节，如果研发仅仅盯着TEE而不了解TEE整个上下游链路和产品的对外使用形态，也很难说服客户。
```

